{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Qmo37/VAE_MNIST/blob/master/VAE_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "github-sync"
      },
      "source": [
        "## 🔄 GitHub Auto-Sync\n",
        "\n",
        "This cell automatically fetches the latest VAE_MNIST.py from GitHub and syncs it to this notebook.\n",
        "Please run this cell first to ensure you're using the latest code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "github-sync-code"
      },
      "outputs": [],
      "source": [
        "# GitHub Auto-Sync Functionality\n",
        "# ==============================\n",
        "# This cell automatically detects GitHub repository and fetches the latest VAE_MNIST.py\n",
        "\n",
        "print(\"🚀 Setting up GitHub auto-sync...\")\n",
        "\n",
        "# Install required packages\n",
        "!pip install jupytext requests > /dev/null 2>&1\n",
        "\n",
        "import requests\n",
        "import jupytext\n",
        "import json\n",
        "import re\n",
        "from IPython.display import display, Markdown, clear_output\n",
        "import os\n",
        "\n",
        "def auto_detect_github_info():\n",
        "    \"\"\"Auto-detect GitHub repository information\"\"\"\n",
        "    try:\n",
        "        # Get GitHub info from Colab metadata\n",
        "        with open('/content/.config/configurations/default_config.json', 'r') as f:\n",
        "            config = json.load(f)\n",
        "            github_url = config.get('github_url', '')\n",
        "    except:\n",
        "        github_url = ''\n",
        "    \n",
        "    # If auto-detection fails, use the notebook's GitHub link\n",
        "    if not github_url:\n",
        "        # Extract info from this notebook's GitHub link\n",
        "        github_url = \"https://github.com/Qmo37/VAE_MNIST\"\n",
        "    \n",
        "    # Parse GitHub URL\n",
        "    match = re.search(r'github\\.com/([^/]+)/([^/]+)', github_url)\n",
        "    if match:\n",
        "        username = match.group(1)\n",
        "        repo_name = match.group(2)\n",
        "        return username, repo_name\n",
        "    \n",
        "    return 'Qmo37', 'VAE_MNIST'  # Default values\n",
        "\n",
        "def fetch_latest_python_file():\n",
        "    \"\"\"Fetch the latest Python file from GitHub\"\"\"\n",
        "    username, repo_name = auto_detect_github_info()\n",
        "    \n",
        "    # Try different branch names\n",
        "    branches = ['main', 'master']\n",
        "    \n",
        "    for branch in branches:\n",
        "        url = f\"https://raw.githubusercontent.com/{username}/{repo_name}/{branch}/VAE_MNIST.py\"\n",
        "        print(f\"🔍 Trying to fetch: {url}\")\n",
        "        \n",
        "        try:\n",
        "            response = requests.get(url, timeout=10)\n",
        "            if response.status_code == 200:\n",
        "                print(f\"✅ Successfully fetched file (branch: {branch})\")\n",
        "                return response.text, url\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Branch {branch} fetch failed: {e}\")\n",
        "            continue\n",
        "    \n",
        "    return None, None\n",
        "\n",
        "def sync_python_to_notebook(python_content):\n",
        "    \"\"\"Convert Python content to notebook format\"\"\"\n",
        "    try:\n",
        "        # Save Python file\n",
        "        with open('VAE_MNIST_latest.py', 'w', encoding='utf-8') as f:\n",
        "            f.write(python_content)\n",
        "        \n",
        "        # Convert using jupytext\n",
        "        notebook = jupytext.read('VAE_MNIST_latest.py')\n",
        "        \n",
        "        print(f\"📓 Successfully converted, contains {len(notebook.cells)} cells\")\n",
        "        \n",
        "        # Show code preview\n",
        "        print(\"\\n📋 Python file content preview:\")\n",
        "        lines = python_content.split('\\n')\n",
        "        preview_lines = min(20, len(lines))\n",
        "        \n",
        "        for i, line in enumerate(lines[:preview_lines]):\n",
        "            print(f\"{i+1:2d}: {line}\")\n",
        "        \n",
        "        if len(lines) > preview_lines:\n",
        "            print(f\"... {len(lines) - preview_lines} more lines\")\n",
        "        \n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"❌ Conversion failed: {e}\")\n",
        "        return False\n",
        "\n",
        "# Main sync process\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"🔄 Starting GitHub sync process\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Step 1: Fetch latest file\n",
        "python_content, github_url = fetch_latest_python_file()\n",
        "\n",
        "if python_content:\n",
        "    print(f\"\\n📥 File size: {len(python_content)} characters\")\n",
        "    print(f\"🔗 Source: {github_url}\")\n",
        "    \n",
        "    # Step 2: Convert to notebook format\n",
        "    if sync_python_to_notebook(python_content):\n",
        "        print(\"\\n✨ Sync completed!\")\n",
        "        \n",
        "        # Step 3: Execute Python file\n",
        "        print(\"\\n🚀 Executing latest VAE_MNIST.py...\")\n",
        "        print(\"=\"*50)\n",
        "        \n",
        "        try:\n",
        "            exec(python_content)\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Execution error: {e}\")\n",
        "            print(\"\\n💡 You can manually copy the code to cells below and execute\")\n",
        "        \n",
        "    else:\n",
        "        print(\"❌ Sync failed, will use default notebook code\")\n",
        "else:\n",
        "    print(\"❌ Unable to fetch GitHub file, will use default notebook code\")\n",
        "    print(\"\\n💡 Please check:\")\n",
        "    print(\"   • GitHub repository exists and is accessible\")\n",
        "    print(\"   • VAE_MNIST.py file is in the repository root\")\n",
        "    print(\"   • Network connection is working\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"🎯 GitHub sync process completed\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# VAE MNIST - Variational Autoencoder for Handwritten Digit Reconstruction\n",
        "\n",
        "Using Colab to demonstrate how to use Variational Autoencoder (VAE) to reconstruct MNIST handwritten digits.\n",
        "\n",
        "## Assignment Requirements\n",
        "- Use MNIST dataset\n",
        "- Implement VAE (Encoder + Decoder)\n",
        "- Reparameterization trick\n",
        "- Adam optimizer\n",
        "- Display average loss per epoch\n",
        "- Output reconstruction images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## 1. Environment Setup and Package Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "imports",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68c2629e-bf59-488a-9b43-485df80884ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Install required packages (if needed)\n",
        "# !pip install torch torchvision matplotlib\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model"
      },
      "source": [
        "## 2. VAE Model Definition\n",
        "\n",
        "### Model Architecture\n",
        "```\n",
        "Encoder: 784 → 400 → (mu=20, logvar=20)\n",
        "Decoder: 20 → 400 → 784\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vae_class",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09c7730a-ad6c-4091-aad9-e09d76385310"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameters: 652,824\n"
          ]
        }
      ],
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, input_dim=784, hidden_dim=400, latent_dim=20):\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        # Encoder: 784 -> 400 -> (mu, logvar)\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
        "\n",
        "        # Decoder: latent_dim -> 400 -> 784\n",
        "        self.fc3 = nn.Linear(latent_dim, hidden_dim)\n",
        "        self.fc4 = nn.Linear(hidden_dim, input_dim)\n",
        "\n",
        "    def encode(self, x):\n",
        "        \"\"\"Encoder: converts input to latent space parameters\"\"\"\n",
        "        h1 = F.relu(self.fc1(x))\n",
        "        mu = self.fc_mu(h1)\n",
        "        logvar = self.fc_logvar(h1)\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        \"\"\"Reparameterization trick: z = mu + std * epsilon\"\"\"\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        \"\"\"Decoder: converts latent variable back to image\"\"\"\n",
        "        h3 = F.relu(self.fc3(z))\n",
        "        return torch.sigmoid(self.fc4(h3))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x.view(-1, 784))\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n",
        "\n",
        "# Initialize model\n",
        "model = VAE().to(device)\n",
        "print(f'Model parameters: {sum(p.numel() for p in model.parameters()):,}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loss"
      },
      "source": [
        "## 3. Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "loss_function"
      },
      "outputs": [],
      "source": [
        "def vae_loss(recon_x, x, mu, logvar):\n",
        "    \"\"\"\n",
        "    VAE loss = Reconstruction loss + KL divergence\n",
        "    \"\"\"\n",
        "    # Reconstruction loss (Binary Cross Entropy)\n",
        "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
        "    \n",
        "    # KL divergence loss\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    \n",
        "    return BCE + KLD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data"
      },
      "source": [
        "## 4. Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "data_loading",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd9c4ef7-1b6f-4b91-9d4d-c4d4b9d1e5f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading MNIST dataset...\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        }
      ],
      "source": [
        "print(\"Loading MNIST dataset...\")\n",
        "\n",
        "# Data transforms\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "# Load datasets\n",
        "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
        "\n",
        "# Data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "optimizer"
      },
      "source": [
        "## 5. Optimizer Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "optimizer_setup"
      },
      "outputs": [],
      "source": [
        "# Adam optimizer (as required)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "training"
      },
      "source": [
        "## 6. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "train_function"
      },
      "outputs": [],
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    \n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass\n",
        "        recon_batch, mu, logvar = model(data)\n",
        "        \n",
        "        # Calculate loss\n",
        "        loss = vae_loss(recon_batch, data, mu, logvar)\n",
        "        \n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "        \n",
        "        # Progress logging\n",
        "        if batch_idx % 200 == 0:\n",
        "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
        "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item() / len(data):.6f}')\n",
        "    \n",
        "    # Calculate average loss for epoch\n",
        "    avg_loss = train_loss / len(train_loader.dataset)\n",
        "    print(f'====> Epoch: {epoch} Average loss: {avg_loss:.4f}')\n",
        "    return avg_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "training_loop",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42af86bc-c1b3-4f4f-b4a4-7e8f8b6f4c92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting training...\n",
            "==================================================\n",
            "Train Epoch: 1 [0/60000 (0%)]    Loss: 550.088562\n",
            "Train Epoch: 1 [25600/60000 (43%)] Loss: 174.723694\n",
            "====> Epoch: 1 Average loss: 163.9552\n",
            "Train Epoch: 2 [0/60000 (0%)]    Loss: 142.521164\n",
            "Train Epoch: 2 [25600/60000 (43%)] Loss: 124.748375\n",
            "====> Epoch: 2 Average loss: 119.8043\n",
            "Train Epoch: 3 [0/60000 (0%)]    Loss: 115.562973\n",
            "Train Epoch: 3 [25600/60000 (43%)] Loss: 116.046196\n",
            "====> Epoch: 3 Average loss: 113.2526\n",
            "Train Epoch: 4 [0/60000 (0%)]    Loss: 109.762146\n",
            "Train Epoch: 4 [25600/60000 (43%)] Loss: 111.064453\n",
            "====> Epoch: 4 Average loss: 109.9656\n",
            "Train Epoch: 5 [0/60000 (0%)]    Loss: 107.883606\n",
            "Train Epoch: 5 [25600/60000 (43%)] Loss: 109.236076\n",
            "====> Epoch: 5 Average loss: 107.8644\n",
            "==================================================\n",
            "Training completed!\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nStarting training...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "epochs = 5  # As mentioned in original requirements\n",
        "losses = []\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    avg_loss = train(epoch)\n",
        "    losses.append(avg_loss)\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"Training completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "visualization"
      },
      "source": [
        "## 7. Results Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "results_viz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "outputId": "4b86a81b-58b6-4e7d-9e88-2e4c9b2e4ed7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating reconstruction results...\n",
            "Reconstruction results saved as 'reconstruction.png'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x300 with 16 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+gAAAEjCAYAAACR7LYDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABGb0lEQVR4nO3dd5gV5fkG4PfslN47K9JsVxBBxa4YKxo1YrAQe4mQxBJbYmzRGGuixhi7JjH2X2zBgooVGzZAQUGKgiJI74AlbO++2aefc86U74+jJ5+zuIjszszOfe5rrg0yc+bM2zN7du9+9X2LrjFqCBAREREREVH8NOItgIiIiIiIiIjYQCciIiIiIiKyhhhBJyIiIiIiIsoLbKATERERERERZQE20ImIiIiIiIjyABvoRERERERERHmADXQiIiIiIiKiPMAGOhEREREREVEeYAOdiIiIiIiIKA+wgU5EREREREQUMzNnzkRRURGee+65XHJD0Fg52ot4c8P3Kzek4q2AiOJlzZo1uO+++1BRUYFgMIgtW7bg0EMPxY033oi6dese9P1z55qDBw/G3Llzc8vGGOzatQvNmzeHruvY/40N0TlnH/J5XW7Q2pKuteHamEIuF5/eUOO4AJgRhR5/9/t6cO6hXaB0pQKhAMH7vbGf8/eD5vxAvu3QNE1fDPJa5/T/8OU6p8eG9BtAxf5NmZLzGjtOBL6fhOVYoKsq5L4DtJZqfOy1E7EvdQyuvO8WnH7GWdCMGOyMDq13Frrm1k/Q2ZbUlrb94xLvN4QFXW0JWyubWO97MIxcG3a/mTiGrqMjg6K7f3lUn31gH2r9zd9GfY6j7b8ov1k+ekmBZgc3PJVrQ0tH6WmZJoLDCk9BZzFKdxR3OXQIB9j/W2jHp7CkYhguP1f9/99UjqJKYyKKzcvLbqE+z8EI/qUy/7oEuQHPcqxcA/3ffOhbdHJDrOVTKuFfmIjguzJKnr0xnvLyxvfff48777wT3bp1w0033YQOHTrA5/Ph+++/x+OPP47vvvsOEydOPOhj5M6JY8eOxdKlS3PJt99+ixdffBEPPfQQzjjjjFyuW7duB32O/1n/S9c0c+1xWFdBMOsNQNOBcMsFiIXaWF+rq/3c1drtjQIqhAZhxH2/YcO2rXjj1e+hOWquc/Ag52g6WOlDgdCB4BQHtNY0sGQYUusSUzDCLsLOHVWtUKjGxjafyBIXNEeFriUgfAkY8Rgxg3s6LCwJKyEy0r0d5Vxey8XyqBXMeA7GKZZ7bTsWdN2I0t8/q+sqkCVpOKXJUJzd7B98ve8ZfLNvBDY9+g4a7rsVrb69BoqMdl8cCOZfA4drmO5qGLsPfr2VbxOE/+t1K2MJ8Pft8NpHKk9BjsJhVl6/XFd6ApjYCWC9sUCUlkqhGTaEgwWo7BYKYAgATrMW1t8BtBw13W5BQKcNOKklIAgZCFu1dJgFhC2SccfpgK8Gh4bOBhSOK8gI+4AuZ0RpmvWnNg95rGfHlmzDgY9W0eiiBjdoCNwIKOGz3LTlMhWl7yHj0iGF8LdH6aMmv/hfq5HfOPl6KE+bHG9rAAAAAC1JREFUeemll1BTU4M33ngDqVQql7/mmmsOeiNcfHy7du0wfPhwAPz7WrFiBQBgxIgR+Z3bvX496urq8MYbb+Ree+21WLhwIR588MEDnCgaypTUH1v++U7+8h74l2//sL+KN6C5IILfLFZXHxoqKqpw44x8cPk6OH+4FrsO3Y5kx32oGdwM38K8jPfm

